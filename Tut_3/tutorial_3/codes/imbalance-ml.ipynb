{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data in the Abalone Dataset \n",
    "This notebook demonstrates how to handle imbalanced data using the Abalone dataset and compare the performance of machine learning model before and after dealing with imbalance data.\n",
    "## Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "# fetch abalone dataset \n",
    "abalone = fetch_ucirepo(id=1)\n",
    "\n",
    "# split into features and target \n",
    "X = abalone.data.features \n",
    "y = abalone.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Class Distribution Before Handling Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class distribution before handling imbalance: {Counter(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and Standardise Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns)\n",
    "data= pd.get_dummies(X, columns=['Sex'], prefix='', prefix_sep='')\n",
    "data = data.drop(['I'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# standardise the features \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model Before Handling Imbalance\n",
    "RandomForestClassifier will be train before applying any technique to handle imbalance and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model before handling class imbalance\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set and evaluate performance \n",
    "y_pred_before = rf_model.predict(X_test)\n",
    "print(\"Classification Report Before Handling Imbalance:\\n\", classification_report(y_test, y_pred_before))\n",
    "print(\"Confusion Matrix Before Handling Imbalance:\\n\",confusion_matrix(y_test, y_pred_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if Data is Under fit or Over fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(x, y):\n",
    "    # generate and plot learning curve\n",
    "    train_sizes, train_scores, val_scores = learning_curve(rf_model, x, y, cv=5, n_jobs=-1)\n",
    "    \n",
    "    # calculate mean and std deviation for training and validation scores \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores,axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_scores_mean, label='Training Score', color='blue')\n",
    "    plt.plot(train_sizes, val_scores_mean, label='Validation Score', color='orange')\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color='orange')\n",
    "    plt.title('Learning Curve for RandomForestClassifier')\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "check_dataset(data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalance Using Random Oversampling\n",
    "Using Random Oversampling to balance the class distribution by duplicating samples from the minority class in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use SMOTE to handle imbalance\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# check class distribution after handling imbalance\n",
    "print(f\"Class distribution after Random Oversampling: {Counter(y_train_resampled)}\")\n",
    "check_dataset(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model After Handling Imbalance\n",
    "After applying Random Oversampling, the model will be trained again and evaluate its performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on resampled data\n",
    "rf_model_resampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict on test set and evaluate performance after resampling\n",
    "y_pred_after = rf_model_resampled.predict(X_test)\n",
    "print(\"Classification Report After Handling Imbalance:\\n\", classification_report(y_test, y_pred_after))\n",
    "print(\"Confusion Matrix After Handling Imbalance:\\n\", confusion_matrix(y_test, y_pred_after))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
